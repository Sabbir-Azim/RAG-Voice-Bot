ğŸ™ï¸ RAG VoiceBot â€” Chat with Your PDF using OpenAI + Chroma + Streamlit

ğŸ§  A Retrieval-Augmented Generation (RAG) based voice assistant that lets you ask questions from any PDF using your voice â€” it converts your speech to text, searches your document using embeddings, and replies back in both text and speech.

ğŸš€ Features

âœ… Voice Input (Speech-to-Text) â€” Ask your questions verbally.
âœ… RAG Retrieval â€” Answers grounded in your uploaded PDF data.
âœ… Chroma Vector Store â€” Local and persistent vector database (no API timeout).
âœ… Text-to-Speech Output â€” Bot responds with a natural voice.
âœ… Streamlit Interface â€” Simple, clean, and interactive web UI.
âœ… OpenAI-Powered Intelligence â€” Uses GPT and embedding models from OpenAI.

ğŸ—ï¸ Tech Stack
Component	Library / Tool
LLM	OpenAI GPT (via langchain-openai)
Vector DB	Chroma
App Framework	Streamlit
Speech-to-Text	streamlit-mic-recorder
Text-to-Speech	gTTS
PDF Loader	PyPDF2, langchain_community
Environment	python-dotenv
ğŸ“¦ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/rag-voicebot.git
cd rag-voicebot

2ï¸âƒ£ Create a Virtual Environment
python -m venv venv
source venv/bin/activate    # On Windows: venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add Environment Variables

Create a .env file in your project root:

OPENAI_API_KEY=your_openai_api_key_here


âš ï¸ You must have a valid OpenAI API key
.

â–¶ï¸ Usage

Run the Streamlit app:

streamlit run app.py


Then:

1ï¸âƒ£ Upload a PDF file ğŸ“„
2ï¸âƒ£ Click Process Document to embed and store in Chroma
3ï¸âƒ£ Click the ğŸ¤ Mic button to ask a question aloud
4ï¸âƒ£ The bot will reply with text + audio answer ğŸ”Š

ğŸ§© Project Structure
rag-voicebot/
â”œâ”€â”€ app.py                # Main Streamlit application
â”œâ”€â”€ .env                  # Environment variables (API key)
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ chroma_db/            # Local Chroma vector store
â””â”€â”€ README.md             # Documentation

ğŸ§  How It Works

PDF Upload: You upload your document.

Chunking & Embedding: The text is split into chunks and converted into embeddings using OpenAI.

Storage in Chroma: These embeddings are stored in a local vector database (Chroma).

Voice Query: Your voice input is transcribed into text using streamlit-mic-recorder.

RAG Pipeline: The bot retrieves relevant document chunks and sends them to the GPT model for an answer.

Voice Output: The response is converted back to speech with gTTS and played automatically.

ğŸ› ï¸ Configuration

Modify settings in the Config class inside app.py:

class Config:
    EMBEDDING_MODEL = "text-embedding-3-small"
    CHAT_MODEL = "gpt-4o-mini"
    CHUNK_SIZE = 500
    CHUNK_OVERLAP = 100
    LANGUAGE = "en"
    CHROMA_PERSIST_DIR = "./chroma_db"

ğŸ—£ï¸ Future Improvements

 Add multilingual support (input in any language, output in English).

 Add memory-based chat context.

 Deploy on Streamlit Cloud or Hugging Face Spaces.

 Replace gTTS with real-time voice using OpenAI TTS.

ğŸ¤ Contributing

Pull requests and feature suggestions are always welcome!
To contribute:

Fork the repo

Create your feature branch (git checkout -b feature-name)

Commit your changes (git commit -m "Add new feature")

Push and open a pull request

ğŸ“œ License

This project is licensed under the MIT License â€” see the LICENSE
 file for details.

ğŸ’¡ Acknowledgements

OpenAI
 for LLMs & embeddings

LangChain
 for RAG pipeline

Chroma
 for local vector DB

Streamlit
 for UI

gTTS
 for text-to-speech